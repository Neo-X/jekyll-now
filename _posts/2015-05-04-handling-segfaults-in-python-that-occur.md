---
layout: post
title: Handling Segfaults in Python that occur in custom C++ libraries
date: '2015-05-04T00:03:00.000-07:00'
author: Glen B
tags: 
modified_time: '2015-05-04T12:01:36.434-07:00'
blogger_id: tag:blogger.com,1999:blog-2030049895335802245.post-485865010738923664
blogger_orig_url: http://fracturedplane.blogspot.com/2015/05/handling-segfaults-in-python-that-occur.html
---

I am using a rather large C++ library to run some simulations. I have wrapped a function that calls this library which results in a large amount of processing. Very rarely and somewhat randomly the C++ library will segfault. It is not the point to debug the library because this simulation process views a segmentation similar to a failed test cases and the libraries <i>scores</i><i> </i>will reflect this error. <br /><br />Instead what I want to do is gracefully handle this segfault. The default behaviour in python is for the process to hang. Python is calling a library that runs a bunch of processing and python will wait until this function returns or a exception is thrown. However in the case I describe neither of these events occur.<br /><br />Lets start with some basic C++ code:<br /><br /><pre><code><br />extern "C" {<br /><br />&nbsp;&nbsp;&nbsp; int raise_a_fault(int r)<br />&nbsp;&nbsp;&nbsp; {<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; std::cout &lt;&lt; "r is "&lt;&lt; r &lt;&lt; std::endl;<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if (r &gt; 3)<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; {<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; volatile int *p = reinterpret_cast<volatile int="">(0);<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; *p = 0x1337D00D; // force a segfault<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // raise(SIGSEGV); // this was not effective enough<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; else<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; {<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return r;<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; }<br />}</volatile>&nbsp; </code></pre><br />This C++ library function will force a segmentation fault if r is greater than 3.<br /><br />I am using the ctypes library from python to link to the C++ library<br /><br /><br /><pre><code><br />from ctypes import cdll<br />lib = cdll.LoadLibrary('./libFoo.so')</code></pre><pre><code>from multiprocessing import Pool </code></pre><pre><code>&nbsp;</code></pre><pre><code>def raise_a_fault(dummy):<br />&nbsp;&nbsp;&nbsp; return lib.raise_a_fault(dummy)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code></pre><pre><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code></pre><pre><code>p = Pool(1)</code></pre><pre><code>items = [1, 2, 3, 4, 5]</code></pre><pre><code>results = p.map(raise_a_fault, items) </code></pre><pre><code><br />print results<br /></code></pre><br />This script will terminate with "Segmentation fault (core dumped)". raise_a_fault() will not return anything and the interpreter will exit. Now instead what if I want to run this over a number of processes to speed up processing time.<br /><br /><pre><code><br /></code><code><code><br />from ctypes import cdll<br />lib = cdll.LoadLibrary('./libFoo.so')</code></code></pre><pre><code><code>from multiprocessing import Pool </code><code>&nbsp;</code></code></pre><pre><code><code>def raise_a_fault(dummy):<br />&nbsp;&nbsp;&nbsp; return lib.raise_a_fault(dummy)&nbsp;&nbsp;</code></code></pre><pre><code><code>&nbsp;</code></code></pre><pre><code><code></code><code>p = Pool(1)</code></code></pre><pre><code><code>items = [1, 2, 3, 4, 5, 4, 3, 2, 1, 10, 2]</code></code></pre><pre><code><code>results = p.map(raise_a_fault, items) </code><code></code><br />print results<br /></code></pre><br />This will never terminate. The subprocess used in the pool with fault and exit without returning a value and the map function will wait, patiently, for a return value. For me I can't even end the script with crtl+c. I have to use ctrl+z which ends up leaving a orphaned process behind.<br /><br />One supposed solution is to add a new signal handler to check for Segmentation fault signals<br /><br /><code><code>from ctypes import cdll lib = cdll.LoadLibrary('./libFoo.so')</code></code><br /><pre><code><code>from multiprocessing import Pool </code><code>&nbsp;</code></code></pre><pre><code><code>def raise_a_fault(dummy):<br />&nbsp;&nbsp;&nbsp; return lib.raise_a_fault(dummy)&nbsp;&nbsp;</code></code></pre><pre><code><code>&nbsp;</code></code></pre><pre><code><code>def sig_handler(signum, frame):<br />    print "segfault"<br />    return None </code></code></pre><pre><code><code>signal.signal(signal.SIGSEGV, sig_handler)</code></code></pre><pre><code><code>&nbsp;</code></code></pre><pre><code><code></code><code>p = Pool(1)</code></code></pre><pre><code><code>items = [1, 2, 3, 4, 5, 4, 3, 2, 1, 10, 2]</code></code></pre><pre><code><code>results = p.map(raise_a_fault, items) </code><code></code><br />print results<br /></code></pre><br /><br />This still has some odd issues. There seems to be some race condition that leads the processes to consume the resources of the processor but the processes do not advance. It might have something to do with this bug <a href="http://bugs.python.org/issue8296" target="_blank">bug</a>. Generally passing signals to child processes is tricky business in Python. Child processes will ignore <i>signals</i> when they are busy processing worker functions. I have seen suggestions to instead add a timeout on to the call to p.map().(timeout=1). This had no effect for me.<br /><br />A different solution that I have used before has more promise. This solution involves replacing map with apply_async(). In this case non of the signal handling is needed.<br /><br /><br /><br /><code><code>from ctypes import cdll lib = cdll.LoadLibrary('./libFoo.so')</code></code><br /><pre><code><code>from multiprocessing import Pool </code><code>&nbsp;</code></code></pre><pre><code><code>&nbsp;</code></code></pre><pre><code><code>def print_results(result):<br />    print "callback result: ***************** " + str (result)<br />&nbsp;</code></code></pre><pre><code><code>def raise_a_fault(dummy):<br />    print "raise_a_fault, pid " + str(os.getpid())<br />    try:<br />        return lib.raise_a_fault(dummy)<br />    except Exception as inst:<br />        print "The fault is " + str(inst)<br />        # ctypes.set_errno(-2)</code></code></pre><pre><code><code>&nbsp;</code></code></pre><pre><code><code></code><code>processes_pool = Pool(2)<br />print "main, pid " + str(os.getpid())<br />items = [1, 2, 3, 4, 5, 4, 3, 2, 1, 10, 2]<br /><br />try:<br />    for item in items:<br /><br />        try:</code></code></pre><pre><code><code>            # this ensures the results come out in the same order the the experiemtns are in this list.<br />            result = processes_pool.apply_async(raise_a_fault, args = (item, ), callback = print_results)<br />            result.get(timeout=1)<br />        except Exception as inst:<br />            print "The exception is " + str(inst)<br />            continue<br />    processes_pool.join()<br />    <br />except Exception as inst:<br />    print "The Out exception is " + str(inst)</code></code></pre><pre><code><code> </code></code></pre><pre><code><code>print "All Done!" </code></code></pre><br />The output:<br /><br /><br />main, pid 23466<br />raise_a_fault, pid 23467<br />r is 1<br />callback result: ***************** 1<br />raise_a_fault, pid 23468<br />r is 2<br />callback result: ***************** 2<br />raise_a_fault, pid 23467<br />r is 3<br />callback result: ***************** 3<br />raise_a_fault, pid 23468<br />r is 4<br />The exception is <br />raise_a_fault, pid 23467<br />r is 5<br />The exception is <br />raise_a_fault, pid 23475<br />r is 4<br />The exception is <br />raise_a_fault, pid 23479<br />r is 3<br />callback result: ***************** 3<br />raise_a_fault, pid 23483<br />r is 2<br />callback result: ***************** 2<br />raise_a_fault, pid 23479<br />r is 1<br />callback result: ***************** 1<br />raise_a_fault, pid 23483<br />r is 10<br />The exception is <br />raise_a_fault, pid 23479<br />r is 2<br />callback result: ***************** 2<br />The Out exception is <br />All Done!<br /><br /><br /><br />This method is almost great. We have the output we want but we have to use a timeout. Some, including myself, don't want to have to specify a definitive timeout where we expect the processing to be complete. It is not easy to find a nice solution to this problem, there are some <a href="https://bugs.python.org/issue3999" target="_blank">bugs</a> that make catching segfaults difficult.<br /><br />Unfortunately, this story has a tragic end. There does not seem to be good support for trapping SIGSEGV or many other signals in Python. I also tried some options in the C++ code. You can change how signals are handled in the C++ code but all that can effectively be done is to raise another signal. Useful exceptions can not be throw from a signal handler because they are essentially on a different stack frame. The solution presented seems to work the best. It does have the added benefit that processes do not <i>crash</i>. By not crashing I am referring to having the process exit() resulting in the process pool reduce the number of processes in the pool which could eventually lead to no processes available.<br /><br />The code I used to play around with possible solutions can be found <a href="https://github.com/Neo-X/PythonCppWrapping" target="_blank">here</a>.<br /><br />References:<br /><ol><li>https://docs.python.org/3/library/ctypes.html</li><li>http://stackoverflow.com/questions/1717991/throwing-an-exception-from-within-a-signal-handler </li></ol>